# vozctl Roadmap

## Architecture

### Two-Model Pipeline

```
Voice â†’ [Parakeet STT] â†’ raw text â†’ [Decision SLM] â†’ action
                                          â†‘
                                   window context
                                   (app, cursor, mode, language)
```

1. **Parakeet TDT 0.6B** â€” local speech-to-text via sherpa-onnx. Fast, accurate, private.
2. **Decision SLM** â€” tiny model that classifies intent (command vs dictation) and formats output based on active window context.

### System Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   User Voice                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Audio Capture Layer (platform-specific)  â”‚
â”‚   CoreAudio / WASAPI / PulseAudio / ALSA        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VAD (Silero via sherpa-onnx)         â”‚
â”‚         Voice activity â†’ audio segments          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         STT Engine (sherpa-onnx)                 â”‚
â”‚   Models: Parakeet TDT 0.6B / Whisper / custom  â”‚
â”‚   Batch mode. Local-only.                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ raw transcript
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Command Parser / Grammar Engine           â”‚
â”‚   Mode detection: command vs. dictation          â”‚
â”‚   Grammar rules, formatters                      â”‚
â”‚   (snake_case, camelCase, etc.)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚ command                 â”‚ dictation
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Action Dispatcher  â”‚  â”‚   Text Output Layer    â”‚
â”‚  OS automation      â”‚  â”‚   CGEvent key injectionâ”‚
â”‚  LLM intent bridge  â”‚  â”‚                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Technical Decisions

- **Phase 0:** Python (speed to dogfood). Rust rewrite planned for Phase 1+.
- **STT:** sherpa-onnx with Parakeet TDT 0.6B (batch, not streaming)
- **VAD:** Silero via sherpa-onnx
- **Key injection:** macOS CGEvent (Phase 0). Cross-platform abstraction later.
- **Command matching:** exact â†’ parameterized â†’ formatter â†’ NATO â†’ dictation fallback

---

## Phases

### Phase 0: Spike âœ… (In Progress)

**Goal:** Working proof of concept. "Say 'go to line 50' and it works."

- [x] sherpa-onnx + Parakeet TDT integration
- [x] Silero VAD â†’ batch STT pipeline
- [x] ~20 hardcoded commands (navigation, mode switching, formatters)
- [x] Hotkey toggle (Ctrl+Shift+V)
- [x] macOS CGEvent key injection
- [x] State machine: PAUSED â†” COMMAND â†” DICTATION
- [x] NATO alphabet for spelling
- [x] Self-test (`--self-test`)
- [ ] Latency target: <800ms p95

**Scope:** macOS only, single mic, Python, no grammars.

### Phase 1: Core MVP (6â€“8 weeks)

**Goal:** Usable daily driver for enthusiasts.

- [ ] Vim voice grammar â€” natural phrases â†’ vim motions ([#1](https://github.com/grizzdank/vozctl/issues/1))
- [ ] Custom command definitions (YAML or Python)
- [ ] Improved mode switching (confidence-based)
- [ ] Menubar app (macOS)
- [ ] User-configurable mic selection
- [ ] Expanded command set (50+ covering 80% of use cases)
- [ ] Rust rewrite of audio + VAD hot path (latency)

### Phase 2: IDE Integration (8â€“12 weeks)

- [ ] Neovim plugin (priority â€” vim grammar from Phase 1)
- [ ] Zed integration (via remote commands / keystroke simulation)
- [ ] Command/dictation mode switching via Decision SLM
- [ ] Code-aware formatting (language-dependent)
- [ ] Context-aware output (terminal vs editor vs prose)

### Phase 3: Polish & Platform (3â€“6 months)

- [ ] Linux support
- [ ] Windows support
- [ ] JetBrains plugin
- [ ] LLM intent bridge ("refactor this function" â†’ action)
- [ ] Custom wake words
- [ ] User-trainable vocabulary
- [ ] Multi-language dictation (Parakeet v3)

### Phase 4: Community & Scale (6â€“12 months)

- [ ] Shareable command packs
- [ ] Community command repository
- [ ] Cloud model option (for users without GPU)
- [ ] Team/enterprise features
- [ ] Mobile companion

---

## Effort Reality Check

| Component | Complexity | Notes |
|-----------|-----------|-------|
| Audio capture | ğŸ”´ High | Platform-specific. macOS permissions, Windows audio routing, Linux fragmentation |
| STT integration | ğŸŸ¢ Low | sherpa-onnx does the heavy lifting |
| Command grammar parser | ğŸŸ¡ Medium | Need extensible format without reimplementing Talon internals |
| Mode switching | ğŸ”´ High | #1 UX challenge. False positives destroy trust |
| IDE plugins | ğŸŸ¡ Medium | Neovim straightforward, JetBrains less so |
| Cross-platform | ğŸ”´ High | Audio, accessibility APIs, text injection all differ per OS |
| LLM integration | ğŸŸ¡ Medium | API calls easy; reliable intent extraction from noisy speech is hard |

---

## Design Principles

1. **Local-first** â€” no cloud dependency for core functionality
2. **Natural language** â€” if you'd feel stupid saying it out loud, the grammar is wrong
3. **Unix philosophy** â€” do one thing well, compose with other tools
4. **Open everything** â€” engine, commands, models. No closed-source bottlenecks
5. **Dogfood early** â€” Phase 0 exists to use daily, not to demo
